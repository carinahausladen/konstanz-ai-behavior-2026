# Reproducible Research, Analysis Quality & Figure-Centered Storytelling

In this session we go beyond *just* making code run again—we’ll design research that others can reliably **reproduce**, **inspect**, and **extend**, while also sharpening the **statistical rigor** and **narrative clarity** of our analyses and figures.

## Focus areas
- **Analysis quality:** checking model/analysis choices; assessing whether additional **statistical tests** (assumptions, power, multiple-comparisons, effect sizes, uncertainty) are needed.
- **Figure-first communication:** do the figures make the point? Are scales, annotations, and comparisons clear?
- **Open sharing:** what “good” GitHub and Hugging Face repositories look like.

## In-class activity (small groups)
1. **Figure critique:** Each group reviews a set of figures from another project.  
   - What is the main claim? Does the figure *demonstrate* it?  
   - Would a different visualization better answer the question?
2. **Stats check:** For the same analysis, identify what statistical tests (if any) are appropriate, the assumptions they require, and whether they’re met. Propose improvements (e.g., effect sizes, CIs, corrections).
3. **Repro review:** Inspect the repository layout and reproducibility “surface”
