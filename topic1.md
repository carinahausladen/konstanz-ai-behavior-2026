# Bias and Fairness in LLMs / VLMs

---

## üîë Core Concepts

1. **CLIP (Contrastive Language‚ÄìImage Pretraining)**
   - Dual encoders, joint embedding space, contrastive learning.

2. **Embeddings**
   - Vectors as compressed meaning.
   - Intuition: ‚Äúsemantic geography.‚Äù

3. **Cosine Similarity**
   - Geometric intuition ‚Üí direction matters, not length.

4. **Social Perception Theories**
   - Psychological dimensions: warmth, competence, agency, etc.

5. **Operationalization**
   - Turning theory into vectors.
   - Causally Measuring alignment between text (theory) and images (model outputs).

---

## üìñ Core Readings

- Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., & Sutskever, I. (2021). *Learning Transferable Visual Models From Natural Language Supervision* (CLIP). [Link](https://arxiv.org/abs/2103.00020). 
- Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). *Semantics derived automatically from language corpora contain human-like biases* (WEAT). [Link](https://www.science.org/doi/pdf/10.1126/science.aal4230)
- Hausladen, C. I., Knott, M., Camerer, C. F., & Perona, P. (2024). *Social perception of faces in a vision-language model.*  [Link](https://dl.acm.org/doi/pdf/10.1145/3715275.3732041)
- Fiske, S. T., Cuddy, A. J., & Glick, P. (2002). *Stereotype Content Model: Warmth and Competence as universal dimensions of social perception.*  [Link](https://d1wqtxts1xzle7.cloudfront.net/49013872/Warmth_and_Competence_as_Universal_Dimen20160921-3310-1lvtfe0-libre.pdf?1474469807=&response-content-disposition=inline%3B+filename%3DWarmth_and_Competence_as_Universal_Dimen.pdf&Expires=1758630848&Signature=J0~E420wGbv20fSrXaTC6wK7YDSj0jAeACA-ORvHlCNLodr98qOxCrXoOZhikOjGduTj-DRhYUVYqVHJ0cGK~3dVIiMEKlcj~f8fcGKx0s0Nt6GH5afywe-eZs8o~zHhwO4XlwO74UC0ckdwP2dGUj75A7DigQLDZm5my-U8YGba~h-k20BkhdVzZa0kKq9UcpkOGCXcqDqNDoLNEDex1soxu-5dcMJPmfTtGsbqrmlgGUMxScFhsbOmzqfa2v9OdxfQIuV5fg9UYXetyaNhcY-Il6VexdXxmXKhXrfSkJYyVxlZ0MeilZtF4Ar66dfeSUvQQuFCGYP5NiNI85Sw-A__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)
- Bailey, A. H. (2022). *Based on billions of words on the internet, people = men.* Science Advances. [Link](https://www.science.org/doi/full/10.1126/sciadv.abm2463)  
- Bai, X., Wang, A., Sucholutsky, I., & Griffiths, T. L. (2025). *Explicitly unbiased large language models still form biased associations.* [Link](https://doi.org/10.1073/pnas.2416228122)

---

## üìä Project Ideas & Datasets

- Explore new LLMs such as **DeepSeek** or **ApertusAI (Swiss)** for bias analysis.  

---

## üéì Tutorials & Resources

- [Primer on LLM Embeddings ‚Äî Hugging Face](https://huggingface.co/spaces/hesamation/primer-llm-embedding?section=what_are_embeddings)  
